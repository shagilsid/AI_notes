# Building Model
## Steps
1. Define: What type of model will it be?
2. Fit: Capture patterns from provided date. This is the heart of modelling
3. Predict: Predict
4. Evaluate: Determine how accurate the model's predictions are.

```python
from sklearn.tree import DecisionTreeRegressor

# Define model. Specify a number for random_state to ensure same results each run
melbourne_model = DecisionTreeRegressor(random_state=1)

# Fit model
melbourne_model.fit(X, y)
```

`random_state`: specifying a number ensures you get the same results in each run.


## Making predictions
```python
print("Making predictions for the following 5 houses:")
print(X.head())
print("The predictions are")
print(melbourne_model.predict(X.head()))
```
# Model Validation
How good your model is?
Measuring model quality is the key to iteratively improving models.
There are many metrics for summarizing model quality.
## Mean Absolute Error (MAE)
`|error|=actual-predicted`
We then take the *average* of those absoulte errors.
>On Average, our predictions are off by about X

```python
from sklearn.tree import DecisionTreeRegressor
# Define model
melbourne_model = DecisionTreeRegressor()
# Fit model
melbourne_model.fit(X, y)
```
Once we have a model, here is how we calculate the mean absolute error:

```python
from sklearn.metrics import mean_absolute_error

predicted_home_prices = melbourne_model.predict(X)
mean_absolute_error(y, predicted_home_prices)
```

## In Sample Score
**Problem**:
The Pattern dereived from training data, the model will appear accurate in the training data.
BUt if this pattern doesn't hold when the model sees new data, the model woulb be very inaccurate when used in practise.

**Model's practical value come from making predictions on new data. We have to measure performance on data that wasn't used to build the model.**

The most straight forwards way to do thos is to exclude some data from model-building process, and then use those to test the model's accuracy on data it hasn't seen before.
This data is called **validation data**

## Coding it using Decision tree
A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.
 
scikit-learn library: `train_test_split`

```python
rom sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
# Define model
melbourne_model = DecisionTreeRegressor()
# Fit model
melbourne_model.fit(train_X, train_y)

# get predicted prices on validation data
val_predictions = melbourne_model.predict(val_X)
print(mean_absolute_error(val_y, val_predictions))
```

## Coding it using Random Forest
The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters.

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

forest_model = RandomForestRegressor(random_state=1)
forest_model.fit(train_X, train_y)
melb_preds = forest_model.predict(val_X)
print(mean_absolute_error(val_y, melb_preds))
```
