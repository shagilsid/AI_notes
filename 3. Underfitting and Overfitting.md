# Experimenting with Different Models
What alternatives you have for models?

# Overfitting
Where a model matches the training data almost perfectly, but does poorly in **validation and other new data**.

# Underfitting
When a model fails to capture important distictions and patterns in the data, so it performs poorly even in **training data**

> We have to find the sweet spot between underfitting and overfitting.
![Sweet spot between underfitting and overfitting](http://i.imgur.com/AXSEOfI.png)

# Control under and overfitting
Using parameter max_leaf_nodes here:
```python
from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor

def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val = model.predict(val_X)
    mae = mean_absolute_error(val_y, preds_val)
    return(mae)
```

We can use a for-loop to compare the accuracy of models built with different values for max_leaf_nodes.

```python
for max_leaf_nodes in [5, 50, 500, 5000]:
    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))
```
- Max leaf nodes: 5  		 Mean Absolute Error:  347380
- Max leaf nodes: 50  		 Mean Absolute Error:  258171
- Max leaf nodes: 500  		 Mean Absolute Error:  243495
- Max leaf nodes: 5000  		 Mean Absolute Error:  254983

- Of the options listed, 500 is the optimal number of leaves.
